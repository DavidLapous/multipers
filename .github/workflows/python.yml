# This workflow will upload a Python Package using Twine when a release is created
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python#publishing-to-package-registries

# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

name: Build, test, and Push to PyPI

on:
  push:


jobs:
  linux:
    name: linux_compile
    # container: gudhi/pip_for_gudhi:latest # container allows to compile for older abis, but is not easy to setup...
    strategy:
      matrix:
        # python-version: ['310']
        python-version: ["3.10", "3.11"]
        os: ["ubuntu-latest", "macos-latest"] #windows fails for some reasons
    runs-on: ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v3
    # - name: Set up Python # Inside the docker now
    #   uses: actions/setup-python@v4
    #   with:
    #     python-version: ${{ matrix.python-version }}
    - name: Setup miniconda
      uses: conda-incubator/setup-miniconda@v2
      with:
        python-version:  ${{ matrix.python-version }}
        activate-environment: build_test_env
        channels: conda-forge
        # channel-priority: true
    # - name: Add conda to system path
    #   run: |
    #     # $CONDA is an environment variable pointing to the root of the miniconda directory
    #     echo $CONDA/bin >> $GITHUB_PATH
    - name: Install build and test dependencies
      shell: bash -el {0}
      run: |
        conda install mamba -c conda-forge
        mamba install python=${{matrix.python-version}} pip -c conda-forge
        mamba install numpy gudhi cython boost boost-cpp tbb tbb-devel pytest scikit-learn matplotlib build cxx-compiler joblib tqdm scipy -c conda-forge
        pip install pykeops filtration-domination --upgrade
    - name: Build package
      shell: bash -el {0}
      run: |
        python setup.py sdist
        python setup.py build_ext -j2 --inplace
        pip wheel . --wheel-dir dist
    - name: Install and Test
      shell: bash -el {0}
      run: |
        pip install dist/*.whl
        pytest multipers/tests

    # - name: Upload wheels
    #   uses: actions/upload-artifact@v3
    #   with:
    #     name: wheels
    #     path: wheelhouse
    - name: Upload sources and wheel
      uses: actions/upload-artifact@v3
      with:
        name: sources
        path: dist
  
  send_to_pypi:
    name: Send sources and wheels
    runs-on: ubuntu-latest
    needs: [ linux ]
    steps:
      - uses: actions/download-artifact@v3
        with:
          name: sources
      # - uses: actions/download-artifact@v3
      #   with:
      #     name: wheels
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Auditwheel
        run: |
          pip install auditwheel --upgrade
          for wheel_file in multipers*linux*.whl; do
            auditwheel show $wheel_file
            auditwheel repair $wheel_file --plat manylinux_2_34_x86_64
            rm $wheel_file
          done
          mv wheelhouse/*.whl . # retrieves repaired wheels
      - name: Publish to PyPI
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
        run: |
          pip install --upgrade pip twine
          twine upload --skip-existing *.tar.gz # sources
          twine upload --skip-existing *.whl    # wheels     
