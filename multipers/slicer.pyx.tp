{{py:

"""
Vine and non-vine slicers.
both type have the same interface, defined the slicer.pyx file
"""


import pickle

with open("build/tmp/_slicer_names.pkl", "rb") as f:
  slicers=pickle.load(f)


}}

from multipers.simplex_tree_multi import SimplexTreeMulti, SimplexTreeMulti_type
import multipers
from typing import Optional,Literal
import multipers.io as mio
import multipers.grids as mpg
import threading
import os 

from multipers.slicer cimport *
from multipers.filtrations cimport *
from multipers.filtration_conversions cimport *
## TODO: these two are not needed, remove that by updating rank code.
from multipers.point_measure import sparsify
from multipers.ml.signed_betti import rank_decomposition_by_rectangles

import numpy as np
cimport cython
# python_value_type = np.float32
from typing import Union
from cython.operator cimport dereference

## WARNING : This is repeated in the pxd file ...
python_indices_type=np.int32
python_tensor_dtype = np.int32

global available_slicers
available_slicers = tuple((
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  {{PYTHON_TYPE}},
{{endfor}}
))

global available_columns
available_columns = set((
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  "{{COL}}",
{{endfor}}
))

global available_dtype
available_dtype = set([
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  "{{PYTHON_TYPE}}",
{{endfor}}
])


global column_type
_column_type = Literal[
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  "{{COL}}",
{{endfor}}
]

global _slicers_type
Slicer_type = Union[
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  {{PYTHON_TYPE}},
{{endfor}}
]

global _valid_dtypes
_valid_dtype = Union[
{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}
  {{PY_VALUE_TYPE}},
{{endfor}}
]

{{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT,FILTRATION_TYPE  in slicers}}

#------------------------------------------------------------------------------
cdef class {{PYTHON_TYPE}}:
    cdef {{CTYPE}} truc
    cdef public vector[vector[double]] filtration_grid
    cdef public int minpres_degree ## TODO : maybe change directly the degree in the minpres ?

    def __repr__(self):
        return f"slicer[type={self.dtype},num_param={self.num_parameters},vineyard={self.is_vine},kcritical={self.is_kcritical},is_squeezed={self.is_squeezed},is_minpres={self.is_minpres},max_dim={self.dimension}]" 

    @property
    def is_squeezed(self)->bool:
        return self.filtration_grid.size() > 0 and self.filtration_grid[0].size() > 0
    @property
    def is_minpres(self)->bool:
        return self.minpres_degree>=0
    @staticmethod
    def _inf_value():
        return np.asarray(np.inf,dtype={{PY_VALUE_TYPE}}) if issubclass({{PY_VALUE_TYPE}},np.floating) else np.iinfo({{PY_VALUE_TYPE}}).max

    def get_ptr(self):
        """
        Returns a pointer to the underlying C++ slicer.
        """
        return <intptr_t>(&self.truc)
    def _from_ptr(self, intptr_t slicer_ptr):
        self.truc = dereference(<{{CTYPE}}*>(slicer_ptr))
        return self

    {{if IS_SIMPLICIAL}}
    def __init__(self, st=None):
        """
        Constructs a slicer from a simplex tree.
        """
        pass
    def __cinit__(self, st=None):
        if st is None:
            return
        cdef intptr_t ptr = st.thisptr
        cdef Simplex_tree_multi_interface[{{FILTRATION_TYPE}},{{C_VALUE_TYPE}}]* st_ptr = <Simplex_tree_multi_interface[{{FILTRATION_TYPE}},{{C_VALUE_TYPE}}]*>(ptr)
        self.truc = {{CTYPE}}(st_ptr)
        self.minpres_degree = -1
    {{elif IS_KCRITICAL}}
    def __init__(self, generator_maps=[], generator_dimensions=[], filtration_values=[]):        
        """
        Constructs a slicer from
         - scc-like blocks 
         or 
         - generator maps (Iterable of list of ints)
         - generator dimensions (Iterable of int)
         - filtration values (Iterable of filtration values)
        """
        pass
    def __cinit__(self, generator_maps=[], generator_dimensions=[], filtration_values=[]):
        """
        Cython constructor
        """
        if len(generator_maps)>0 and len(generator_dimensions) == 0 and len(filtration_values) == 0:
          from multipers._slicer_meta import _blocks2boundary_dimension_grades
          generator_maps, generator_dimensions, filtration_values = _blocks2boundary_dimension_grades(
                  generator_maps,
                  inplace=False,
              )
        cdef uint32_t num_generators = len(generator_maps)
        cdef vector[vector[uint32_t]] c_generator_maps
        cdef vector[Multi_critical_filtration[{{C_VALUE_TYPE}}]] c_filtration_values
        for stuff in generator_maps:
            c_generator_maps.push_back(<vector[uint32_t]>(stuff))
        cdef Multi_critical_filtration[{{C_VALUE_TYPE}}] cf
        cdef One_critical_filtration[{{C_VALUE_TYPE}}] inf
        inf[0] = -inf[0]
        for F in filtration_values:
            cf.push_to_least_common_upper_bound(inf)
            for f in F:
                cf.add_generator(_py21c_{{SHORT}}(f))
            c_filtration_values.push_back(cf)
        cdef vector[int] c_generator_dimensions = generator_dimensions
        assert num_generators == c_generator_maps.size() == c_filtration_values.size(), "Invalid input, shape do not coincide."
        self.truc = {{CTYPE}}(c_generator_maps,c_generator_dimensions, c_filtration_values)
        self.minpres_degree = -1
    {{else}}
    def __init__(self, generator_maps=[], generator_dimensions=[], filtration_values=[]):        
        """
        Constructs a slicer from
         - generator maps (Iterable of list of ints)
         - generator dimensions (Iterable of int)
         - filtration values (Iterable of filtration values)
        """
        pass
    def __cinit__(self, generator_maps=[], generator_dimensions=[], filtration_values=[]):
        """
        Cython constructor
        """
        cdef uint32_t num_generators = len(generator_maps)
        cdef vector[vector[uint32_t]] c_generator_maps
        cdef vector[One_critical_filtration[{{C_VALUE_TYPE}}]] c_filtration_values
        for stuff in generator_maps:
            c_generator_maps.push_back(<vector[uint32_t]>(stuff))
        for f in filtration_values:
            # cf.clear()
            # for truc in f:
            #     cf.push_back(truc)
            c_filtration_values.push_back(_py21c_{{SHORT}}(f))
        cdef vector[int] c_generator_dimensions = generator_dimensions
        assert num_generators == c_generator_maps.size() == c_filtration_values.size(), "Invalid input, shape do not coincide."
        self.truc = {{CTYPE}}(c_generator_maps,c_generator_dimensions, c_filtration_values)
        self.minpres_degree = -1
    {{endif}}
    
    def copy(self)->{{PYTHON_TYPE}}:
        """
        Returns a copy of the slicer.
        """
        copy_ = {{PYTHON_TYPE}}()
        copy_.truc = self.truc
        copy_.minpres_degree = self.minpres_degree
        copy_.filtration_grid = self.filtration_grid
        return copy_
    def get_barcode(self):
        """
        Returns the current barcode.
        """
        return self.truc.get_barcode()
    def push_to_line(self, basepoint, direction=None)->{{PYTHON_TYPE}}:
        """
        Pushes the current slicer to the line defined by a basepoint and an optional direction.
        If the direction is not provided, it is assumed to be diagonal.
        """
        cdef Line[{{C_VALUE_TYPE}}] line
        if direction is None:
            line = Line[{{C_VALUE_TYPE}}](_py21c_{{SHORT}}(basepoint))
        else:
            line = Line[{{C_VALUE_TYPE}}](_py21c_{{SHORT}}(basepoint),_py21c_{{SHORT}}(direction))
        self.truc.push_to(line)
        return self

    @staticmethod
    cdef _threshold_bcs(vector[vector[pair[{{C_VALUE_TYPE}}, {{C_VALUE_TYPE}}]]] bcs):
        return tuple(np.fromiter((a for a in stuff if a.first < {{PYTHON_TYPE}}._inf_value()),  dtype=np.dtype(({{PY_VALUE_TYPE}},2))) for stuff in bcs)
    @staticmethod
    def _bc_to_full(bcs, basepoint, direction=None):
        # i, (b sv d), coords 
        basepoint = np.asarray(basepoint)[None,None,:]
        direction = 1 if direction is None else np.asarray(direction)[None,None,:]
        return tuple(bc[:,:,None]*direction + basepoint for bc in bcs)

    def persistence_on_line(self,basepoint,direction=None, bool keep_inf=True, bool full=False):
        """
        Computes the persistence on a line L defined by 
         - a basepoint (num_parameters,) array
         - an optional direction (num_parameters,) array
        
        Warning: This is not parallelizable. Use `persitence_on_lines`.
        """
        self.push_to_line(basepoint,direction)
        self.truc.compute_persistence()
        if keep_inf:
            bcs = tuple(np.asarray(stuff, dtype = {{PY_VALUE_TYPE}}) for stuff in self.truc.get_barcode())
        else:
            bcs = {{PYTHON_TYPE}}._threshold_bcs(self.truc.get_barcode())

        if full:
            bcs = {{PYTHON_TYPE}}._bc_to_full(bcs, basepoint, direction)
        return bcs

    def persistence_on_lines(self, basepoints=None, directions=None, bool keep_inf=True, bool full=False):
        """
        Same as `persistence_on_line`, but with vineyards operation between
        lines if `self.is_vine`, and in parallel otherwise.
        """
        cdef vector[vector[{{C_VALUE_TYPE}}]] c_basepoints
        cdef vector[pair[vector[{{C_VALUE_TYPE}}], vector[{{C_VALUE_TYPE}}]]] c_truc
        cdef vector[vector[vector[pair[{{C_VALUE_TYPE}}, {{C_VALUE_TYPE}}]]]] c_out 
        if directions is None:
            c_basepoints = basepoints
            with nogil:
                c_out = self.truc.persistence_on_lines(c_basepoints)
        else:
            c_truc = zip(basepoints,directions)
            with nogil:
                c_out = self.truc.persistence_on_lines(c_truc)
        cdef int num_bc = c_basepoints.size()
        
        if keep_inf:
            out = tuple(tuple(np.asarray(y, dtype = {{PY_VALUE_TYPE}}) for y in x) for x in c_out)
        else:
            out = tuple({{PYTHON_TYPE}}._threshold_bcs(x) for x in c_out)

        if full:
            _dirs = [None]*len(basepoints) if directions is None else directions 
            out = tuple({{PYTHON_TYPE}}._bc_to_full(bcs, bp, dir) for bcs, bp, dir in zip(out,basepoints,_dirs))
        return out





    def compute_persistence(self,one_filtration=None)->{{PYTHON_TYPE}}:
        """
        Computes the current persistence, or the persistence
        given by the filtration one_filtration (num_generators,).
        """
        if one_filtration is not None:
            self.truc.set_one_filtration(one_filtration)
        # TODO: Later
        # if len(degrees)>0:
        #     self.truc.compute_persistence(degrees)
        # else:
        #     self.truc.compute_persistence()
        self.truc.compute_persistence()
        return self
        # return self.truc.get_barcode()
    def get_barcode(self):
        """
        Returns the barcode of the current 1d-persistence.
        """
        return self.truc.get_barcode()
    def sliced_filtration(self,basepoint, direction=None):
        """
        Computes the filtration on a line L defined by 
         - a basepoint (num_parameters,) array
         - an optional direction (num_parameters,) array
        """
        self.push_to_line(basepoint,direction)
        return np.asarray(self.truc.get_one_filtration())
    def __len__(self):
        return self.truc.num_generators()
    @property
    def num_generators(self):
        return self.truc.num_generators()
    @property
    def num_parameters(self):
        return self.truc.num_parameters()
    @property
    def info(self):
        print(self.truc.to_str().decode())
    def filtration_bounds(self) -> np.ndarray:
        """
        Computes the bounding box of the current multifiltration.
        """
        cdef pair[One_critical_filtration[{{C_VALUE_TYPE}}],One_critical_filtration[{{C_VALUE_TYPE}}]] box = self.truc.get_bounding_box()
        cdef cnp.ndarray[{{C_VALUE_TYPE}}, ndim=1] a = _ff21cview_{{SHORT}}(&box.first)
        cdef cnp.ndarray[{{C_VALUE_TYPE}}, ndim=1] b = _ff21cview_{{SHORT}}(&box.second)
        return np.asarray([a,b])
    def get_filtrations_values(self)->np.ndarray:
        """
        Returns the current filtration values of the slicer.
        """
        cdef vector[One_critical_filtration[{{C_VALUE_TYPE}}]] v = self.truc.get_filtration_values()
        out = _vff21cview_{{SHORT}}(v, copy=True, duplicate=self.num_parameters)
        return np.asarray(out)
    def get_filtration_grid(self,grid_strategy:str="exact", **infer_grid_kwargs):
        return mpg.compute_grid(
                self.get_filtrations_values().T,
                strategy=grid_strategy,
                **infer_grid_kwargs,
            )
    def get_filtrations(self):
        """
        Returns a view of the filtration values, as a list of numpy arrays.
        """
        {{if IS_KCRITICAL}}
        return _vff2kcview_{{SHORT}}(self.truc.get_filtrations(), copy=True, duplicate=self.num_parameters)
        {{else}}
        return _vff21cview_{{SHORT}}(self.truc.get_filtrations(), copy=True, duplicate=self.num_parameters)
        {{endif}}

    def get_dimensions(self)-> np.ndarray:
        """
        Returns the ordered dimensions of the generators.
        """
        return np.asarray(self.truc.get_dimensions())
    @property 
    def dimension(self)-> int:
        """
        Returns the maximum dimension of the complex.
        """
        return self.get_dimensions()[-1] if len(self)>0 else -np.inf
    def prune_above_dimension(self,int max_dimension)->{{PYTHON_TYPE}}:
        """
        Prunes the generators above a given dimension.
        """
        self.truc.prune_above_dimension(max_dimension)
        return self
    def get_boundaries(self)->tuple[tuple]:
        """
        Returns the boundaries of the generators.
        """
        return tuple(tuple(b) for b in self.truc.get_boundaries())
    def grid_squeeze(self, filtration_grid=None, grid_strategy="exact", resolution:Optional[int]=None, bool coordinates=True, bool inplace = False, bool force=False)->{{PYTHON_TYPE[:-3]+"i32"}}|{{PYTHON_TYPE}}:
        """
        Coarsen the filtration values on a grid. This is necessary to compute some invariants.

        If the filtration grid is not given, it is infered from filtration values,
        using the :func:`multipers.grids.compute_grid` function, whose args are
          - grid_strategy:str see `multipers.grids.available_strategies`. Defaults to exact.
          - resolution:int if strategy is not exact.

         - inplace:bool if true, does the operation inplace, i.e., doesn't return a copy.
        """
        if not force and self.is_squeezed:
            raise ValueError("The slicer seems to be already squeezed. Use force=True to resqueeze.")
        if filtration_grid is None:
            filtration_grid = mpg.compute_grid(
                    self.get_filtrations_values().T,
                    strategy=grid_strategy,
                    resolution=resolution)
        cdef vector[vector[{{C_VALUE_TYPE}}]] grid = filtration_grid
        if inplace or not coordinates:
            self.truc.coarsen_on_grid_inplace(grid, coordinates)
            self.filtration_grid = filtration_grid
        else:
          {{if COL is None}}
          raise ValueError("WIP")
          {{else}}
          out = {{PYTHON_TYPE[:-3]+"i32"}}()
          out.truc = self.truc.coarsen_on_grid(grid)
          out.filtration_grid = filtration_grid
          out.minpres_degree = self.minpres_degree
          return out
          {{endif}}
        return self
    def minpres(self,
        int degree=-1, 
        list[int] degrees=[],
        str backend:Literal["mpfree", "2pac"]="mpfree", 
        str slicer_backend:Literal["matrix","clement","graph"]="matrix",
        bool vineyard={{IS_VINE}}, 
        id :Optional[str] = None,
        dtype = {{PY_VALUE_TYPE}},
        **minpres_kwargs
        )->Slicer_type:
        """
        Computes the minimal presentation of the slicer, and returns it as a new slicer.
        See :func:`multipers.slicer.minimal_presentation`.
        """
        new_slicer = minimal_presentation(self, degree=degree, degrees=degrees, backend=backend, slicer_backend=slicer_backend, vineyard=vineyard, id=id, **minpres_kwargs)
        return new_slicer

    @property
    def dtype(self)->type:
      return {{PY_VALUE_TYPE}}
    @property
    def col_type(self)->str:
      return "{{COL}}"
    @property
    def is_vine(self)->bool:
      return {{IS_VINE}}
    @property
    def is_kcritical(self)->bool:
      return {{IS_KCRITICAL}}


    {{if IS_VINE}}
    def vine_update(self,basepoint,direction=None)->{{PYTHON_TYPE}}:
        """
        Updates the barcode, on a line, using the vineyard algorithm.
        """
        self.push_to_line(basepoint,direction)
        self.truc.vineyard_update()
        return self
    def get_representative_cycles(self, bool update=True):
        """
        Returns the representative cycles of the current barcode.
        Recomputes the generators if update=True
        """
        return self.truc.get_representative_cycles(update)
    def get_permutation(self):
        """
        Returns the current generator permutation (w.r.t. vineyard).
        """
        return self.truc.get_current_order()
    {{endif}}

    {{if not IS_KCRITICAL}}
    def build_from_scc_file(self, path:str|os.PathLike, rivet_compatible = False, reverse = False, shift_dimension = 0):
        """
        Builds the slicer from the given scc file. Should be empty before, otherwise will be completely overwritten.
        """
        self.truc.build_from_scc_file(path.encode(encoding="utf-8"), rivet_compatible, reverse, shift_dimension)

    def write_to_scc_file(
            self,
            path:str|os.PathLike,
            num_parameters = -1,
            degree = -1,
            rivet_compatible = False,
            ignore_last_generators = False,
            strip_comments = False,
            reverse = False):
        """
        Writes current slicer to a file in scc format.
        """
        self.truc.write_to_scc_file(path.encode(encoding="utf-8"), num_parameters, degree, rivet_compatible, ignore_last_generators, strip_comments, reverse)
    {{endif}}

    @staticmethod
    def from_bitmap(self):
      raise ValueError("Not implemented.")
{{endfor}}

def from_function_delaunay(
    points,
    grades,
    int degree=-1,
    str backend: Literal["matrix", "clement"] = "matrix",
    bool vineyard=True,
    bool verbose = False,
    bool clear = True,
):
    """
    Given points in $\mathbb R^n$ and function grades, compute the function-delaunay
    bifiltration as a in an scc format, and converts it into a slicer.

    points : (num_pts, n) float array
    grades : (num_pts,) float array
    degree (opt) : if given, computes a minimal presentation of this homological degree first
    backend : slicer backend, e.g. "matrix", "clement"
    vineyard : bool, use a vineyard-compatible backend
    """
    # blocks = mio.function_delaunay_presentation(points, grades, degree=degree, verbose=verbose,clear=clear)
    # s= multipers.Slicer(blocks, backend=backend, vineyard=vineyard)
    s = multipers.Slicer(None, backend=backend, vineyard=vineyard)
    mio.function_delaunay_presentation_to_slicer(s, points, grades, degree=degree, verbose=verbose,clear=clear)
    if degree >0:
        s.minpres_degree = degree
    return s

def slicer2blocks(slicer, int degree = -1, bool reverse=True):
    """
    Convert any slicer to the block format a.k.a. scc format for python
    """
    dims = slicer.get_dimensions()
    num_empty_blocks_to_add = 1 if degree == -1 else dims.min()-degree +1
    _,counts = np.unique(dims, return_counts=True, )
    indices = np.concatenate([[0],counts], dtype=np.int32).cumsum()
    filtration_values = slicer.get_filtrations()
    filtration_values = [filtration_values[indices[i]:indices[i+1]] for i in range(len(indices)-1)]
    boundaries = slicer.get_boundaries()
    boundaries = [boundaries[indices[i]:indices[i+1]] for i in range(len(indices)-1)]
    shift = np.concatenate([[0], indices], dtype=np.int32)
    boundaries = [tuple(np.asarray(x-s, dtype=np.int32) for x in block)  for s,block in zip(shift,boundaries)]
    blocks = [tuple((f,tuple(b))) for b,f in zip(boundaries,filtration_values)]
    blocks = ([(np.empty((0,)),[])]*num_empty_blocks_to_add) + blocks
    if reverse:
        blocks.reverse()
    return blocks

def minimal_presentation(
        slicer,
        int degree = -1, 
        degrees:Iterable[int]=[],
        str backend:Literal["mpfree", "2pac", ""]="mpfree", 
        str slicer_backend:Literal["matrix","clement","graph"]="matrix",
        bool vineyard=True, 
        id :Optional[str] =None,
        dtype=None,
        int n_jobs = -1,
        bool force=False,
        **minpres_kwargs
        ):
    """
    Computes a minimal presentation of the multifiltered complex given by the slicer,
    and returns it as a slicer.
    Backends differents than `mpfree` are unstable.
    """
    if is_slicer(slicer) and slicer.is_minpres and not force:
        from warnings import warn
        warn(f"The slicer seems to be already reduced, from homology of degree {slicer.minpres_degree}.")
        return slicer
    mio._init_external_softwares(requires=[backend])
    if len(degrees)>0:
        from joblib import Parallel, delayed
        def todo(int degree):
            return minimal_presentation(slicer, degree=degree, backend=backend, slicer_backend=slicer_backend, vineyard=vineyard, id=id, **minpres_kwargs)
        return tuple(
          Parallel(n_jobs=n_jobs, backend="threading")(delayed(todo)(d) for d in degrees)
        )
        # return tuple(minimal_presentation(slicer, degree=d, backend=backend, slicer_backend=slicer_backend, vineyard=vineyard, id=id, **minpres_kwargs) for d in degrees)
    assert degree>=0, f"Degree not provided."
    filtration_grid = slicer.filtration_grid if slicer.is_squeezed else None
    if id is None:
        id = str(threading.get_native_id())
    if dtype is None:
        dtype = slicer.dtype
    dimension = slicer.dimension - degree # latest  = L-1, which is empty, -1 for degree 0, -2 for degree 1 etc.
    slicer.write_to_scc_file(path=mio.input_path+id, strip_comments=True, degree=degree-1)
    new_slicer = multipers.Slicer(None,backend=slicer_backend, vineyard=vineyard, dtype=dtype)
    if backend=="mpfree":
        shift_dimension=degree-1
    else:
        shift_dimension=degree
    mio.scc_reduce_from_str_to_slicer(path=mio.input_path+id, slicer=new_slicer, dimension=dimension, backend=backend, shift_dimension=shift_dimension, **minpres_kwargs)
    new_slicer.minpres_degree = degree
    if filtration_grid is not None:
      new_slicer.filtration_grid = filtration_grid
    return new_slicer


def to_simplextree(s:Slicer_type, max_dim:int=-1) -> SimplexTreeMulti_type:
    """
    Turns a --simplicial-- slicer into a simplextree.

    Warning: Won't work for non-simplicial complexes, 
    i.e., complexes $K$ not satisfying 
    $\forall \sigma \in K,\, \mathrm{dim}(\sigma) = |\partial \sigma|-1$
    """
    dims = s.get_dimensions()
    assert np.all(dims[:-1] <= dims[1:]), "Dims is not sorted."
    idx = np.searchsorted(dims, np.unique(dims))
    idx = np.concatenate([idx, [dims.shape[0]]])
    if max_dim>=0:
        idx = idx[:max_dim+2]

    cdef vector[vector[int]] boundaries_ = s.get_boundaries()
    cdef int a
    cdef int b
    if len(idx)>2:
        a = idx[2]
        b = idx[-1]
        for i in range(a, b):
            boundaries_[i] = np.unique(np.concatenate([boundaries_[k] for k in boundaries_[i]]))
    boundaries = [np.asarray(boundaries_[idx[i]:idx[i+1]]).T for i in range(len(idx)-1)]
    boundaries[0] = np.arange(boundaries[0].shape[1])[None,:]
    filtrations = s.get_filtrations()
    num_parameters  = s.num_parameters
    filtrations=tuple(filtrations[idx[i]:idx[i+1]] for i in range(len(idx)-1)) # TODO : optimize ?
    st = SimplexTreeMulti(num_parameters = num_parameters, dtype = s.dtype, kcritical=s.is_kcritical)
    for i in range(len(filtrations)):
        if s.is_kcritical:
          for f in filtrations[i]:
            st.insert(np.asarray(boundaries[i], dtype = np.int32),np.asarray(f, dtype=s.dtype))
        else:
          st.insert_batch(np.asarray(boundaries[i], dtype= np.int32),np.asarray(filtrations[i], dtype=s.dtype))
    return st


def _is_slicer(object input)->bool:
    """
    Checks if the input is a slicer. Equivalent (but faster) to `isinstance(input, multipers.slicer.Slicer_type)`.
    """
    return (False 
        {{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT, FILTRATION_TYPE  in slicers}}
        or isinstance(input, {{PYTHON_TYPE}})
        {{endfor}}
      )
def is_slicer(input, bool allow_minpres=True)->bool:
    if _is_slicer(input):
        return True
    if allow_minpres and isinstance(input, list) or isinstance(input, tuple):
        if len(input)>0 and all((_is_slicer(s) and s.is_minpres for s in input)):
            return True
    return False


def to_blocks(input):
    """
    Converts input to blocks, if possible.
    """
    if is_slicer(input):
      return slicer2blocks(input)
    if isinstance(input, list) or isinstance(input, tuple):
      return input
    from multipers.simplex_tree_multi import is_simplextree_multi
    if is_simplextree_multi(input):
      return input._to_scc()
    if isinstance(input, str) or isinstance(input, os.PathLike):
      return mio.scc_parser(input)
    raise ValueError("Input cannot be converted to blocks.")



cdef dict[tuple[bool,bool,type],object] slicer_dict = {
  {{for CTYPE_H, CTYPE,PYTHON_TYPE, IS_SIMPLICIAL, IS_VINE, IS_KCRITICAL, C_VALUE_TYPE, PY_VALUE_TYPE, COL, SHORT, FILTRATION_TYPE  in slicers}}
  {{if not IS_SIMPLICIAL}}
  ({{IS_VINE}}, {{IS_KCRITICAL}}, np.dtype({{PY_VALUE_TYPE}}), "{{COL}}"): {{PYTHON_TYPE}},
  {{endif}}
  {{endfor}}
}

def get_matrix_slicer(bool is_vineyard, bool is_k_critical, type dtype, str col):
  """
  Given various parameters, returns the specific slicer type associated with them.
  """
  slicer = slicer_dict.get((is_vineyard, is_k_critical, np.dtype(dtype), col), None)
  if slicer is None:
    raise ValueError(f"Unimplemented combo for Matrix : {is_vineyard=}, {is_k_critical=}, {dtype=}")
  return slicer




def _hilbert_signed_measure(slicer, 
    vector[indices_type] degrees, 
    bool zero_pad=False, 
    indices_type n_jobs=0, 
    bool verbose=False,
    # bool expand_collapse=False, 
    # grid_conversion = None,
    ):
  """
  Computes the signed measures given by the decomposition of the hilbert function.

  Input
  -----

   - simplextree:SimplexTreeMulti, the multifiltered simplicial complex
   - degrees:array-like of ints, the degrees to compute
   - n_jobs:int, number of jobs. Defaults to #cpu, but when doing parallel computations of signed measures, we recommend setting this to 1.
   - verbose:bool, prints c++ logs.
  
  Output
  ------
  
  `[signed_measure_of_degree for degree in degrees]`
  with `signed_measure_of_degree` of the form `(dirac location, dirac weights)`.
  """

  assert slicer.is_squeezed, "Squeeze grid first."
  if slicer.is_squeezed:
    grid_shape = np.array([len(f) for f in slicer.filtration_grid])
  else:
      grid_shape = (slicer.filtration_bounds()[1]).astype(python_indices_type)+1
  if zero_pad:
    for i, _ in enumerate(grid_shape):
      grid_shape[i] += 1 # adds a 0
  assert len(grid_shape) == slicer.num_parameters, "Grid shape size has to be the number of parameters."
  grid_shape_with_degree = np.asarray(np.concatenate([[len(degrees)], grid_shape]), dtype=python_indices_type)
  container_array = np.ascontiguousarray(np.zeros(grid_shape_with_degree, dtype=python_tensor_dtype).flatten())
  assert len(container_array) < np.iinfo(np.uint32).max, "Too large container. Raise an issue on github if you encounter this issue. (Due to tensor's operator[])"
  cdef vector[indices_type] c_grid_shape = grid_shape_with_degree
  cdef tensor_dtype[::1] container = container_array
  cdef tensor_dtype* container_ptr = &container[0]
  cdef signed_measure_type out = _compute_hilbert_sm(slicer, container_ptr, c_grid_shape, degrees,n_jobs, verbose, zero_pad)
  pts, weights = np.asarray(out.first, dtype=int).reshape(-1, slicer.num_parameters+1), np.asarray(out.second, dtype=int)
  slices = np.concatenate([np.searchsorted(pts[:,0], np.arange(degrees.size())), [pts.shape[0]] ])
  sms = [
      (pts[slices[i]:slices[i+1],1:],weights[slices[i]:slices[i+1]])
      for i in range(slices.shape[0]-1)
  ]
  return sms


## Rank invariant


## TODO : It is not necessary to do the Möbius inversion in python.
## fill rank in flipped death, then differentiate in cpp, then reflip with numpy.
def _rank_from_slicer(
        slicer, 
        vector[indices_type] degrees,
        bool verbose=False,
        indices_type n_jobs=1,
        bool zero_pad = False,
        grid_shape=None,
        bool plot=False,
        bool return_raw=False,
        ):
    # cdef intptr_t slicer_ptr = <intptr_t>(slicer.get_ptr())
    if grid_shape is None:
        if slicer.is_squeezed:
          grid_shape = np.array([len(f) for f in slicer.filtration_grid])
        else:
            grid_shape = (slicer.filtration_bounds()[1]).astype(python_indices_type)+1
    grid_shape = np.asarray(grid_shape)

    cdef int num_parameters = len(grid_shape)

    if zero_pad:
        for i, _ in enumerate(grid_shape):
            grid_shape[i] += 1 # adds a 0
        # for i,f in enumerate(grid_conversion):
        #     grid_conversion[i] = np.concatenate([f, [mass_default[i]]])

    grid_shape_with_degree = np.asarray(np.concatenate([[len(degrees)], grid_shape, grid_shape]), dtype=python_indices_type)
    container_array = np.ascontiguousarray(np.zeros(grid_shape_with_degree, dtype=python_tensor_dtype).ravel())
    assert len(container_array) < np.iinfo(python_indices_type).max, "Too large container. Raise an issue on github if you encounter this issue. (Due to tensor's operator[])"
    cdef vector[indices_type] c_grid_shape = grid_shape_with_degree
    cdef tensor_dtype[::1] container = container_array
    cdef tensor_dtype* container_ptr = &container[0]

    ## SLICERS
    _compute_rank_invariant(slicer, container_ptr, c_grid_shape, degrees, n_jobs)

    rank = container_array.reshape(grid_shape_with_degree)
    rank = tuple(rank_decomposition_by_rectangles(rank_of_degree, threshold = zero_pad) for rank_of_degree in rank)
    if return_raw:
        return rank
    out = []
    def clean_rank(rank_decomposition):
        (coords, weights) = sparsify(np.ascontiguousarray(rank_decomposition))
        births = coords[:,:num_parameters]
        deaths = coords[:,num_parameters:]
        correct_indices = np.all(births<=deaths, axis=1)
        coords = coords[correct_indices]
        weights = weights[correct_indices]
        return coords, weights

    out = tuple(clean_rank(rank_decomposition) for rank_decomposition in rank)
    return out
