@misc{loiseauxFastStableEfficient2022,
  title = {Fast, {{Stable}} and {{Efficient Approximation}} of {{Multi-parameter Persistence Modules}} with {{MMA}}},
  author = {Loiseaux, David and Carri{\`e}re, Mathieu and Blumberg, Andrew J.},
  year = {2022},
  month = jun,
  doi = {10.48550/arXiv.2206.02026},
  urldate = {2024-04-16},
  abstract = {In this article, we introduce a new parameterized family of topological invariants, taking the form of candidate decompositions, for multi-parameter persistence modules. We prove that our candidate decompositions are controllable approximations: when restricting to modules that can be decomposed into interval summands, we establish theoretical results about the approximation error between our candidate decompositions and the true underlying module in terms of the standard interleaving and bottleneck distances. Moreover, even when the underlying module does not admit such a decomposition, our candidate decompositions are nonetheless stable invariants; small perturbations in the underlying module lead to small perturbations in the candidate decomposition. Then, we introduce MMA (Multipersistence Module Approximation): an algorithm for computing stable instances of such invariants, which is based on fibered barcodes and exact matchings, two constructions that stem from the theory of single-parameter persistence. By design, MMA can handle an arbitrary number of filtrations, and has bounded complexity and running time. Finally, we present empirical evidence validating the generalization capabilities and running time speed-ups of MMA on several data sets.},
  langid = {english},
}

@article{loiseauxFrameworkFastStable2023,
  title = {A {{Framework}} for {{Fast}} and {{Stable Representations}} of {{Multiparameter Persistent Homology Decompositions}}},
  author = {Loiseaux, David and Carri{\`e}re, Mathieu and Blumberg, Andrew},
  year = {2023},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {35774--35798},
  urldate = {2024-03-19},
  langid = {english},
}

@article{loiseauxMultipersMultiparameterPersistence2024,
  title = {Multipers: {{Multiparameter Persistence}} for {{Machine Learning}}},
  shorttitle = {Multipers},
  author = {Loiseaux, David and Schreiber, Hannah},
  year = {2024},
  month = nov,
  journal = {Journal of Open Source Software},
  volume = {9},
  number = {103},
  pages = {6773},
  issn = {2475-9066},
  doi = {10.21105/joss.06773},
  urldate = {2024-11-14},
  abstract = {Loiseaux et al., (2024). multipers: Multiparameter Persistence for Machine Learning. Journal of Open Source Software, 9(103), 6773, https://doi.org/10.21105/joss.06773},
  langid = {english},
}

@article{loiseauxStableVectorizationMultiparameter2023,
  title = {Stable {{Vectorization}} of {{Multiparameter Persistent Homology}} Using {{Signed Barcodes}} as {{Measures}}},
  author = {Loiseaux, David and Scoccola, Luis and Carri{\`e}re, Mathieu and Botnan, Magnus Bakke and Oudot, Steve},
  year = {2023},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {68316--68342},
  urldate = {2024-03-19},
  langid = {english},
}

@inproceedings{scoccolaDifferentiabilityOptimizationMultiparameter2024,
  title = {Differentiability and {{Optimization}} of {{Multiparameter Persistent Homology}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Scoccola, Luis and Setlur, Siddharth and Loiseaux, David and Carri{\`e}re, Mathieu and Oudot, Steve},
  year = {2024},
  month = jul,
  series = {Proceedings of Machine Learning Research},
  volume = {235},
  pages = {43986--44011},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-10-02},
  abstract = {Real-valued functions on geometric data---such as node attributes on a graph---can be optimized using descriptors from persistent homology, allowing the user to incorporate topological terms in the loss function. When optimizing a single real-valued function (the one-parameter setting), there is a canonical choice of descriptor for persistent homology: the barcode. The operation mapping a real-valued function to its barcode is differentiable almost everywhere, and the convergence of gradient descent for losses using barcodes is relatively well understood. When optimizing a vector-valued function (the multiparameter setting), there is no unique choice of descriptor for multiparameter persistent homology, and many distinct descriptors have been proposed. This calls for the development of a general framework for differentiability and optimization that applies to a wide range of multiparameter homological descriptors. In this article, we develop such a framework and show that it encompasses well-known descriptors of different flavors, such as signed barcodes and the multiparameter persistence landscape. We complement the theory with numerical experiments supporting the idea that optimizing multiparameter homological descriptors can lead to improved performances compared to optimizing one-parameter descriptors, even when using the simplest and most efficiently computable multiparameter descriptors.},
  langid = {english},
}
