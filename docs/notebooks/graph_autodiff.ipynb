{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e33932",
   "metadata": {},
   "source": [
    "# Filtration Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2d0850-1f70-4940-ab5a-e4664f74d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import multipers as mp\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from os.path import expanduser\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import multipers.ml.signed_measures as mms\n",
    "import multipers.grids as mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e847e-a800-4a89-977d-7c06500d46e8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cf8f3a-387f-4ad5-8a6a-22af0bf147cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"BZR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3deac8-14a8-4739-958f-2a10e52602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_degree(dataset_name):\n",
    "    from torch_geometric.utils import degree\n",
    "    dataset = TUDataset(expanduser(\"~/Datasets/torch_geometric/\"),dataset_name, use_node_attr=True,cleaned=True)\n",
    "    num_nodes = dataset.edge_index.max()+1 # only this matters, we're computing max_degree\n",
    "    assert not Data(edge_index=dataset.edge_index, num_nodes = num_nodes).is_directed()\n",
    "    a= degree(index = dataset.edge_index[0])\n",
    "    b = degree(index = dataset.edge_index[1])\n",
    "    assert (a==b).all() # because is_directed I guess\n",
    "    max_degree = a.max()\n",
    "    return int(max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa47583-05ef-4171-a46c-2bd9233432ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hschreiber/micromamba/envs/multipers-old/lib/python3.12/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/hschreiber/micromamba/envs/multipers-old/lib/python3.12/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/hschreiber/micromamba/envs/multipers-old/lib/python3.12/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    # T.GDC(diffusion_kwargs={\n",
    "    #     \"method\":\"heat\",\n",
    "    #     \"t\":10,\n",
    "    # }),\n",
    "    T.Constant(1), # Constant_value\n",
    "    T.LocalDegreeProfile(),\n",
    "    # T.OneHotDegree(max_degree=get_max_degree(dataset_name)), # degree before removing edges\n",
    "    T.RemoveDuplicatedEdges(),\n",
    "])\n",
    "dataset = TUDataset(expanduser(\"~/Datasets/torch_geometric/\"),dataset_name, use_node_attr=True,cleaned=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c4a343-9d6f-4d5e-8036-2b19a667c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size=len(dataset)\n",
    "# batch_size=100\n",
    "shuffled_dataset = dataset.shuffle()\n",
    "dataset_size = len(dataset)\n",
    "split = int(0.9*dataset_size)\n",
    "train_dataset, test_dataset = dataset[:split], shuffled_dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f90ec39-a2a3-4ce7-b822-c40cae773844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13092, 56]), torch.Size([1489, 56]), torch.Size([14479, 56]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x.shape, test_dataset.x.shape, dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fb5304-63ca-4c0e-9376-c8a22aead6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = next(iter(DataLoader(dataset, batch_size=len(dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857db108-450e-46bb-84db-c4c3c2221f4b",
   "metadata": {},
   "source": [
    "## Some GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb41536-465e-48fa-bd35-f0d2cfbd8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0812228b-15cd-48f6-a3e6-a235a4d633a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels1 = 3 ## Note: this is the number of parameter on which to compute Multiparameter Persistence; keep it low!\n",
    "first_gcn = GCN(in_channels=train.x.shape[-1], hidden_channels=50, num_layers=5, out_channels=out_channels1, dropout=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f272e92d-ed34-41c8-bb70-a0d8e265ff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14479, 3]), torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "out1 = first_gcn.forward(train.x, train.edge_index, batch = train.batch)\n",
    "out1.shape, out1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75716af-9a6c-4b8b-a27d-ef15be622db8",
   "metadata": {},
   "source": [
    "## Some topological layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc82d63-52c8-4c77-b5b6-ba681b482354",
   "metadata": {},
   "source": [
    "### Torch Graphs to Signed Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e751bc4e-2f61-4686-9863-1af0f7947d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import unbatch, unbatch_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f256f22-af63-4af4-a604-80c78f85e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2SMLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        degrees=[0, 1],\n",
    "        grid_strategy:str = \"exact\",\n",
    "        resolution: int = -1,  # meant to crash if grid needs resolution\n",
    "        n_jobs=-1,  # parallelize signed measure computations\n",
    "        normalize: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.degrees = degrees\n",
    "        self.grid_strategy = grid_strategy\n",
    "        self.resolution = resolution\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    @torch.no_grad\n",
    "    def _simplextree_transform(\n",
    "        self,\n",
    "        nodes_indices,\n",
    "        nodes_filtrations,\n",
    "        edge_indices,\n",
    "        diff_grid,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Given a graph g:Data, and filtrations = [node_filtrations, (opts) edge filtrations],\n",
    "        create the associated simplextree.\n",
    "        \"\"\"\n",
    "        num_parameters = nodes_filtrations.size(1)\n",
    "        numpy_node_filtrations = nodes_filtrations.detach().numpy()\n",
    "        st = mp.SimplexTreeMulti(num_parameters=num_parameters)\n",
    "        nodes = nodes_indices[None, :].detach().numpy()\n",
    "        st.insert_batch(nodes, numpy_node_filtrations)\n",
    "        edges = edge_indices.detach().numpy()\n",
    "        numpy_edges_filtrations = np.empty((0,0), dtype = st.dtype)\n",
    "        st.insert_batch(\n",
    "            edges,numpy_edges_filtrations\n",
    "        )  # empty -> -inf\n",
    "        st = st.grid_squeeze(diff_grid, coordinate_values=True)\n",
    "        \n",
    "        # if num_parameters == 2:\n",
    "        #     st.collapse_edges(-1)\n",
    "        sms = mp.signed_measure(st, degrees=self.degrees, coordinate_measure=True)\n",
    "        return sms\n",
    "\n",
    "    def _get_diff_grids(self, node_filtration_iterable):\n",
    "        from multipers.torch.diff_grids import get_grid\n",
    "        todo = get_grid(self.grid_strategy)\n",
    "        return tuple(todo(x.T, self.resolution) for x in node_filtration_iterable)\n",
    "\n",
    "    @torch.no_grad\n",
    "    def data2coordinate_sms(\n",
    "        self, node_indices, nodes_filtrations, edges_indices, diff_grids\n",
    "    ):\n",
    "        from joblib import Parallel, delayed\n",
    "        sms = Parallel(n_jobs=self.n_jobs, backend=\"threading\")(\n",
    "            delayed(self._simplextree_transform)(\n",
    "                node_index,\n",
    "                nodes_filtration,\n",
    "                edge_index,\n",
    "                diff_grid,\n",
    "            )\n",
    "            for node_index, nodes_filtration, edge_index, diff_grid in zip(\n",
    "                node_indices, nodes_filtrations, edges_indices, diff_grids\n",
    "            )\n",
    "        )\n",
    "        return sms\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, nodes_filtrations, edges_indices, batch_indices, *, simplex_tree_list=None\n",
    "    ):\n",
    "        if batch_indices is None:\n",
    "            nodes_filtrations = [nodes_filtrations]\n",
    "        else:\n",
    "            from torch_geometric.utils import unbatch, unbatch_edge_index\n",
    "            node_indices = unbatch(torch.arange(nodes_filtrations.shape[0]), batch = batch_indices)\n",
    "            nodes_filtrations = unbatch(nodes_filtrations, batch=batch_indices)\n",
    "            edges_indices = unbatch_edge_index(edges_indices, batch=batch_indices)\n",
    "            \n",
    "        grids = self._get_diff_grids(nodes_filtrations)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sms = self.data2coordinate_sms(\n",
    "                node_indices,\n",
    "                nodes_filtrations,\n",
    "                edges_indices,\n",
    "                diff_grids=grids,\n",
    "            )\n",
    "        # Joblib doesn't seem to be possible with pytorch\n",
    "        sms = tuple(\n",
    "            mpg.sms_in_grid(sm, diff_grid) for sm, diff_grid in zip(sms, grids)\n",
    "        )\n",
    "        sms = mms.SignedMeasureFormatter(\n",
    "            unrag=True, deep_format=True, normalize=self.normalize\n",
    "        ).fit_transform(sms)\n",
    "\n",
    "        return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bfb9b60-8139-4ad2-bf31-5a25ba849db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_layer = Graph2SMLayer(normalize = True, degrees=[0,1], n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0ec00d-597c-4135-b49a-97a4ab73319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "sms = topological_layer.forward(out1, train.edge_index, train.batch)\n",
    "sms.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce59ae-a7d3-41d0-ac8f-3058e0d16fc7",
   "metadata": {},
   "source": [
    "### Vectorization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1d4a96-3bba-4ccd-b8b9-e6efb5338de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMConvLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_parameters: int,\n",
    "        num_axis: int,\n",
    "        dtype=torch.float64,\n",
    "        num_convolutions: int|None = None,\n",
    "        resolution:int = 5,\n",
    "        out_channels:int|None=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.num_parameters = num_parameters\n",
    "        self.resolution = resolution\n",
    "        self.num_convolutions = (\n",
    "            num_parameters if num_convolutions is None else num_convolutions\n",
    "        )\n",
    "\n",
    "        biases = torch.stack(\n",
    "            [\n",
    "                torch.diag(torch.rand(self.num_parameters, dtype=dtype))\n",
    "                for _ in range(self.num_convolutions)\n",
    "            ],\n",
    "            dim=0,\n",
    "        ).type(dtype)\n",
    "        self.Rs = nn.Parameter(\n",
    "            # torch.randn(\n",
    "            # torch.rand(\n",
    "            torch.zeros(\n",
    "                (self.num_convolutions, num_parameters, num_parameters),\n",
    "                dtype=dtype,\n",
    "                requires_grad=True,\n",
    "            )\n",
    "            + biases  # Maybe add a multiplicative factor ?\n",
    "        ).type(dtype)\n",
    "        self.pts_to_evaluate = nn.Parameter(torch.stack([\n",
    "            torch.cartesian_prod(*(torch.linspace(0,1,resolution) for _ in range(num_parameters))).type(dtype)[None] \n",
    "            for _ in range(num_axis)\n",
    "        ])).type(dtype) # initially pts on a grid\n",
    "        self.out_channels = num_parameters if out_channels is None else out_channels\n",
    "        self.final_reshape = nn.Sequential(nn.Linear(num_convolutions*num_axis*(resolution**num_parameters),out_channels), nn.ReLU())\n",
    "        \n",
    "    def print_info(self):\n",
    "        print(\"SMConvLayer, bandwidths\")\n",
    "        print(self.Rs)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sms,\n",
    "    ):\n",
    "        from multipers.ml.convolutions import batch_signed_measure_convolutions\n",
    "        kernel_matrices = (\n",
    "            # The KDE implementation expects the inverse of the covariance for multiparameter kernels\n",
    "            (R.T @ R).inverse()\n",
    "            for R in self.Rs\n",
    "        )\n",
    "        ## compute convolutions\n",
    "        convolutions = torch.stack(\n",
    "            [\n",
    "                batch_signed_measure_convolutions(\n",
    "                    sms,\n",
    "                    self.pts_to_evaluate,\n",
    "                    bandwidth=k,\n",
    "                    kernel=\"multivariate_gaussian\",\n",
    "                )\n",
    "                for k in kernel_matrices\n",
    "            ]\n",
    "        )\n",
    "        new_f = convolutions.swapaxes(0,2).flatten(1) # num_data, merged stuff\n",
    "        new_f = self.final_reshape(new_f)\n",
    "        return new_f  # New node filtration values\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "217a551e-70bc-4cf7-bff8-8fd2c1a0879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization_layer = SMConvLayer(num_parameters=first_gcn.out_channels, num_axis=len(topological_layer.degrees), dtype = sms.dtype, num_convolutions = 7, resolution = 5, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ca5384-8638-4ae4-9111-1705aae7c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 1) of formula (d*e)*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,9,2), d=Var(3,1,2), e=Var(4,1,0) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp fd51638efa module ... OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([405, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "vectorization_layer(sms).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a522b-be86-4acd-b868-325dbd0f1cd1",
   "metadata": {},
   "source": [
    "## A graph filtration learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcf4b99-dd10-44bb-bfd5-f2abee496119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe3c817-aac4-43e5-a287-fd5c43fa6ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModel(\n",
       "  (first_gcn): GCN(62, 2, num_layers=2)\n",
       "  (topological_layer): Graph2SMLayer()\n",
       "  (vectorization_layer): SMConvLayer(\n",
       "    (final_reshape): Sequential(\n",
       "      (0): Linear(in_features=1000, out_features=5, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GraphModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels:int,\n",
    "        out_channels:int,\n",
    "        num_parameters:int=2,\n",
    "        hidden_channels:int=50,\n",
    "        num_layers:int=2,\n",
    "        degrees:list[int]=[0,1],\n",
    "        num_convolutions:int = 5,\n",
    "        resolution:int=5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ## in an ideal world, put the parameters in the init\n",
    "        self.first_gcn = GCN(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=num_layers, out_channels=num_parameters)\n",
    "        self.topological_layer = Graph2SMLayer(normalize = True, degrees=[0,1])\n",
    "        self.vectorization_layer = SMConvLayer(num_parameters=num_parameters, num_axis=len(degrees), num_convolutions = num_convolutions, resolution = resolution, out_channels=num_convolutions, dtype = torch.float32)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_convolutions, out_channels), \n",
    "            nn.ReLU(), \n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "    def forward(self,data):\n",
    "        out1 = self.first_gcn.forward(data.x, data.edge_index, batch = data.batch)\n",
    "        sms = self.topological_layer.forward(out1, data.edge_index, data.batch)\n",
    "        out = self.vectorization_layer(sms)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "_stuff = train\n",
    "graphclassifier = GraphModel(\n",
    "    in_channels = _stuff.x.shape[1], \n",
    "    out_channels = np.unique(_stuff.y).shape[0],\n",
    "    num_parameters =2,\n",
    "    resolution=10,\n",
    ")\n",
    "graphclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080f67ea-477f-4f84-8937-227c37b78646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 1) of formula (d*e)*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), d=Var(3,1,2), e=Var(4,1,0) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp 947eef4777 module ... OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6274, 0.3726],\n",
       "        [0.8448, 0.1552],\n",
       "        [0.8258, 0.1742],\n",
       "        [0.8540, 0.1460],\n",
       "        [0.8265, 0.1735]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "graphclassifier(train)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec770ec-50c5-4426-b319-8968e478bee0",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a6dddfc-4901-491a-bd17-00e4b93fc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 200\n",
    "batch_size = len(train_dataset)\n",
    "data_loader = DataLoader(train_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce73fcb-0570-43ca-914e-81b37e3702e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current acc 0.783, loss 0.540761411190033, constant to 0:   0%|                                                                                                                                                       | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (-1/2*((f*(d*e))*(MatVecMult(c,a-b)+VecMatMult(a-b,c))))*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), d=Var(3,1,2), e=Var(4,1,0), f=Var(5,1,1) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp c836920a74 module ... OK\n",
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 1) of formula (1/2*((f*(d*e))*(MatVecMult(c,a-b)+VecMatMult(a-b,c))))*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), d=Var(3,1,2), e=Var(4,1,0), f=Var(5,1,1) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp dd41e8c2a6 module ... OK\n",
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (-1/2*((f*(d*e))*TensorProd(a-b,a-b)))*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), d=Var(3,1,2), e=Var(4,1,0), f=Var(5,1,1) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp d4f9325c2b module ... OK\n",
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (e*f)*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), e=Var(4,1,0), f=Var(5,1,1) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp e25a464c96 module ... OK\n",
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (d*f)*Exp(-1/2*(c|TensorProd(a-b,a-b))) with a=Var(0,2,0), b=Var(1,2,1), c=Var(2,4,2), d=Var(3,1,2), f=Var(5,1,1) ... OK\n",
      "[pyKeOps] Compiling pykeops cpp b01d4ec1ad module ... OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current acc 0.783, loss 0.5107177495956421, constant to 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [05:55<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "graphclassifier.train()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(graphclassifier.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "losses = []\n",
    "with tqdm(range(num_epoch)) as epoch:\n",
    "   for i in epoch:\n",
    "       for stuff in data_loader:\n",
    "            optim.zero_grad()\n",
    "            batch_labels = one_hot(stuff.y).type(torch.float32)\n",
    "            prediction = graphclassifier(stuff)\n",
    "            current_loss = loss(prediction, batch_labels)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                real_classification = prediction.argmax(1)\n",
    "                cst = real_classification[0] if np.unique(real_classification).shape[0] == 1 else None\n",
    "                accuracy = (real_classification == stuff.y).type(torch.float32).mean(0)\n",
    "                losses.append(current_loss.detach().numpy())\n",
    "                epoch.set_description(f\"Current acc {accuracy:.3f}, loss {current_loss.detach().numpy()}, {\"\" if cst is None else f\"constant to {cst}\"}\")\n",
    "            current_loss.backward()\n",
    "            optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8062c6e8-3b61-412e-98fd-777d9e3405be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4109, grad_fn=<DivBackward1>), tensor(0.9268))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphclassifier.eval()\n",
    "test_stuff = next(iter(DataLoader(train_dataset,batch_size=len(test_dataset))))\n",
    "prediction = graphclassifier(test_stuff)\n",
    "verdad = one_hot(test_stuff.y).type(torch.float32)\n",
    "loss(prediction, verdad), (prediction.argmax(1)==test_stuff.y).type(torch.float).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28688f8-55cb-4770-8d73-e620587f4114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
