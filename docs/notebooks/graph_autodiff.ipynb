{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e33932",
   "metadata": {},
   "source": [
    "# Filtration Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2d0850-1f70-4940-ab5a-e4664f74d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import multipers as mp\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from os.path import expanduser\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import multipers.ml.signed_measures as mms\n",
    "import multipers.grids as mpg\n",
    "torch.manual_seed(1)\n",
    "## TODO : fixme\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16285d-badc-44e5-834c-8e2b9ff0b990",
   "metadata": {},
   "source": [
    "This code is not meant to realize state of the art graph classification,\n",
    "but to give an idea on how to use `multipers` in a DL setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e847e-a800-4a89-977d-7c06500d46e8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cf8f3a-387f-4ad5-8a6a-22af0bf147cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MUTAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3deac8-14a8-4739-958f-2a10e52602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_degree(dataset_name):\n",
    "    from torch_geometric.utils import degree\n",
    "    dataset = TUDataset(expanduser(\"~/Datasets/torch_geometric/\"),dataset_name, use_node_attr=True,cleaned=True)\n",
    "    num_nodes = dataset.edge_index.max()+1 # only this matters, we're computing max_degree\n",
    "    assert not Data(edge_index=dataset.edge_index, num_nodes = num_nodes).is_directed()\n",
    "    a= degree(index = dataset.edge_index[0])\n",
    "    b = degree(index = dataset.edge_index[1])\n",
    "    assert (a==b).all() # because is_directed I guess\n",
    "    max_degree = a.max()\n",
    "    return int(max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa47583-05ef-4171-a46c-2bd9233432ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    # T.GDC(diffusion_kwargs={\n",
    "    #     \"method\":\"heat\",\n",
    "    #     \"t\":10,\n",
    "    # }),\n",
    "    T.Constant(1), # Constant_value\n",
    "    T.LocalDegreeProfile(),\n",
    "    # T.OneHotDegree(max_degree=get_max_degree(dataset_name)), # degree before removing edges\n",
    "    T.RemoveDuplicatedEdges(),\n",
    "])\n",
    "dataset = TUDataset(expanduser(\"~/Datasets/torch_geometric/\"),dataset_name, use_node_attr=True,cleaned=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c4a343-9d6f-4d5e-8036-2b19a667c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size=len(dataset)\n",
    "# batch_size=100\n",
    "shuffled_dataset = dataset.shuffle()\n",
    "dataset_size = len(dataset)\n",
    "split = int(0.9*dataset_size)\n",
    "train_dataset, test_dataset = dataset[:split], shuffled_dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f90ec39-a2a3-4ce7-b822-c40cae773844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3027, 7]), torch.Size([336, 7]), torch.Size([3371, 7]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x.shape, test_dataset.x.shape, dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fb5304-63ca-4c0e-9376-c8a22aead6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = next(iter(DataLoader(dataset, batch_size=len(dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857db108-450e-46bb-84db-c4c3c2221f4b",
   "metadata": {},
   "source": [
    "## Some GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb41536-465e-48fa-bd35-f0d2cfbd8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0812228b-15cd-48f6-a3e6-a235a4d633a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels1 = 3 ## Note: this is the number of parameter on which to compute Multiparameter Persistence; keep it low!\n",
    "first_gcn = GCN(in_channels=train.x.shape[-1], hidden_channels=50, num_layers=5, out_channels=out_channels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f272e92d-ed34-41c8-bb70-a0d8e265ff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3371, 3]), torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "out1 = first_gcn.forward(train.x, train.edge_index, batch = train.batch)\n",
    "out1.shape, out1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75716af-9a6c-4b8b-a27d-ef15be622db8",
   "metadata": {},
   "source": [
    "## Some topological layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc82d63-52c8-4c77-b5b6-ba681b482354",
   "metadata": {},
   "source": [
    "### Torch Graphs to Signed Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e751bc4e-2f61-4686-9863-1af0f7947d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import unbatch, unbatch_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f256f22-af63-4af4-a604-80c78f85e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2SMLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        degrees=[0, 1],\n",
    "        grid_strategy:str = \"exact\",\n",
    "        resolution: int = -1,  # meant to crash if grid needs resolution\n",
    "        n_jobs=-1,  # parallelize signed measure computations\n",
    "        normalize: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.degrees = degrees\n",
    "        self.grid_strategy = grid_strategy\n",
    "        self.resolution = resolution\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    @torch.no_grad\n",
    "    def _simplextree_transform(\n",
    "        self,\n",
    "        nodes_indices,\n",
    "        nodes_filtrations,\n",
    "        edge_indices,\n",
    "        diff_grid,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Given a graph g:Data, and filtrations = [node_filtrations, (opts) edge filtrations],\n",
    "        create the associated simplextree.\n",
    "        \"\"\"\n",
    "        num_parameters = nodes_filtrations.size(1)\n",
    "        numpy_node_filtrations = nodes_filtrations.detach().numpy()\n",
    "        st = mp.SimplexTreeMulti(num_parameters=num_parameters)\n",
    "        nodes = nodes_indices[None, :].detach().numpy()\n",
    "        st.insert_batch(nodes, numpy_node_filtrations)\n",
    "        edges = edge_indices.detach().numpy()\n",
    "        numpy_edges_filtrations = np.empty((0,0), dtype = st.dtype)\n",
    "        st.insert_batch(\n",
    "            edges,numpy_edges_filtrations\n",
    "        )  # empty -> -inf\n",
    "        st = st.grid_squeeze(diff_grid, coordinate_values=True)\n",
    "        \n",
    "        if num_parameters == 2:\n",
    "            st.collapse_edges(-1)\n",
    "        sms = mp.signed_measure(st, degrees=self.degrees, coordinate_measure=True)\n",
    "        return sms\n",
    "\n",
    "    def _get_diff_grids(self, node_filtration_iterable):\n",
    "        from multipers.torch.diff_grids import get_grid\n",
    "        todo = get_grid(self.grid_strategy)\n",
    "        return tuple(todo(x.T, self.resolution) for x in node_filtration_iterable)\n",
    "\n",
    "    @torch.no_grad\n",
    "    def data2coordinate_sms(\n",
    "        self, node_indices, nodes_filtrations, edges_indices, diff_grids\n",
    "    ):\n",
    "        from joblib import Parallel, delayed\n",
    "        sms = Parallel(n_jobs=self.n_jobs, backend=\"threading\")(\n",
    "            delayed(self._simplextree_transform)(\n",
    "                node_index,\n",
    "                nodes_filtration,\n",
    "                edge_index,\n",
    "                diff_grid,\n",
    "            )\n",
    "            for node_index, nodes_filtration, edge_index, diff_grid in zip(\n",
    "                node_indices, nodes_filtrations, edges_indices, diff_grids\n",
    "            )\n",
    "        )\n",
    "        return sms\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, nodes_filtrations, edges_indices, batch_indices, *, simplex_tree_list=None\n",
    "    ):\n",
    "        if batch_indices is None:\n",
    "            nodes_filtrations = [nodes_filtrations]\n",
    "        else:\n",
    "            from torch_geometric.utils import unbatch, unbatch_edge_index\n",
    "            node_indices = unbatch(torch.arange(nodes_filtrations.shape[0]), batch = batch_indices)\n",
    "            nodes_filtrations = unbatch(nodes_filtrations, batch=batch_indices)\n",
    "            edges_indices = unbatch_edge_index(edges_indices, batch=batch_indices)\n",
    "            \n",
    "        grids = self._get_diff_grids(nodes_filtrations)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sms = self.data2coordinate_sms(\n",
    "                node_indices,\n",
    "                nodes_filtrations,\n",
    "                edges_indices,\n",
    "                diff_grids=grids,\n",
    "            )\n",
    "        # Joblib doesn't seem to be possible with pytorch\n",
    "        sms = tuple(\n",
    "            mpg.sms_in_grid(sm, diff_grid) for sm, diff_grid in zip(sms, grids)\n",
    "        )\n",
    "        sms = mms.SignedMeasureFormatter(\n",
    "            unrag=True, deep_format=True, normalize=self.normalize\n",
    "        ).fit_transform(sms)\n",
    "\n",
    "        return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bfb9b60-8139-4ad2-bf31-5a25ba849db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_layer = Graph2SMLayer(normalize = True, degrees=[0,1], n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0ec00d-597c-4135-b49a-97a4ab73319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "sms = topological_layer.forward(out1, train.edge_index, train.batch)\n",
    "sms.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce59ae-a7d3-41d0-ac8f-3058e0d16fc7",
   "metadata": {},
   "source": [
    "### Vectorization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1d4a96-3bba-4ccd-b8b9-e6efb5338de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMConvLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_parameters: int,\n",
    "        num_axis: int,\n",
    "        dtype=torch.float64,\n",
    "        num_convolutions: int|None = None,\n",
    "        resolution:int = 5,\n",
    "        out_channels:int|None=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.num_parameters = num_parameters\n",
    "        self.resolution = resolution\n",
    "        self.num_convolutions = (\n",
    "            num_parameters if num_convolutions is None else num_convolutions\n",
    "        )\n",
    "\n",
    "        biases = torch.stack(\n",
    "            [\n",
    "                10*torch.diag(torch.rand(self.num_parameters, dtype=dtype))\n",
    "                for _ in range(self.num_convolutions)\n",
    "            ],\n",
    "            dim=0,\n",
    "        ).type(dtype)\n",
    "        self.Rs = nn.Parameter(\n",
    "            torch.randn(\n",
    "            # torch.rand(\n",
    "            # torch.zeros(\n",
    "                (self.num_convolutions, num_parameters, num_parameters),\n",
    "                dtype=dtype,\n",
    "                requires_grad=True,\n",
    "            )\n",
    "            + biases  # Maybe add a multiplicative factor ?\n",
    "        ).type(dtype)\n",
    "        self.pts_to_evaluate = nn.Parameter(torch.stack([\n",
    "            torch.cartesian_prod(*(torch.linspace(0,1,resolution) for _ in range(num_parameters))).type(dtype)[None] \n",
    "            for _ in range(num_axis)\n",
    "        ])).type(dtype) # initially pts on a grid\n",
    "        self.out_channels = num_parameters if out_channels is None else out_channels\n",
    "        self.final_reshape = nn.Sequential(nn.Linear(num_convolutions*num_axis*(resolution**num_parameters),out_channels), nn.ReLU())\n",
    "        \n",
    "    def print_info(self):\n",
    "        print(\"SMConvLayer, bandwidths\")\n",
    "        print(self.Rs)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sms,\n",
    "    ):\n",
    "        from multipers.ml.convolutions import batch_signed_measure_convolutions\n",
    "        kernel_matrices = (\n",
    "            # This KDE implementation expects the inverse of the covariance for multiparameter kernels\n",
    "            (R.T @ R).inverse()\n",
    "            for R in self.Rs\n",
    "        )\n",
    "        ## compute convolutions\n",
    "        convolutions = torch.stack(\n",
    "            [\n",
    "                batch_signed_measure_convolutions(\n",
    "                    sms,\n",
    "                    self.pts_to_evaluate,\n",
    "                    bandwidth=k,\n",
    "                    kernel=\"multivariate_gaussian\",\n",
    "                )\n",
    "                for k in kernel_matrices\n",
    "            ]\n",
    "        )\n",
    "        new_f = convolutions.swapaxes(0,2).flatten(1) # num_data, merged stuff\n",
    "        new_f = self.final_reshape(new_f)\n",
    "        return new_f  # New node filtration values\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "217a551e-70bc-4cf7-bff8-8fd2c1a0879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization_layer = SMConvLayer(num_parameters=first_gcn.out_channels, num_axis=len(topological_layer.degrees), dtype = sms.dtype, num_convolutions = 7, resolution = 5, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ca5384-8638-4ae4-9111-1705aae7c312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([188, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "vectorization_layer(sms).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a522b-be86-4acd-b868-325dbd0f1cd1",
   "metadata": {},
   "source": [
    "## A graph filtration learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcf4b99-dd10-44bb-bfd5-f2abee496119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe3c817-aac4-43e5-a287-fd5c43fa6ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModel(\n",
       "  (first_gcn): GCN(13, 2, num_layers=2)\n",
       "  (topological_layer): Graph2SMLayer()\n",
       "  (vectorization_layer): SMConvLayer(\n",
       "    (final_reshape): Sequential(\n",
       "      (0): Linear(in_features=400, out_features=2, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GraphModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels:int,\n",
    "        out_channels:int,\n",
    "        num_parameters:int=2,\n",
    "        hidden_channels:int=50,\n",
    "        num_layers:int=2,\n",
    "        degrees:list[int]=[0,1],\n",
    "        num_convolutions:int = 5,\n",
    "        resolution:int=5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ## in an ideal world, put the parameters in the init\n",
    "        self.first_gcn = GCN(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=num_layers, out_channels=num_parameters)\n",
    "        self.topological_layer = Graph2SMLayer(normalize = True, degrees=[0,1])\n",
    "        self.vectorization_layer = SMConvLayer(num_parameters=num_parameters, num_axis=len(degrees), num_convolutions = num_convolutions, resolution = resolution, out_channels=num_convolutions, dtype = torch.float32)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_convolutions, out_channels), \n",
    "            nn.ReLU(), \n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "    def forward(self,data):\n",
    "        out1 = self.first_gcn.forward(data.x, data.edge_index, batch = data.batch)\n",
    "        sms = self.topological_layer.forward(out1, data.edge_index, data.batch)\n",
    "        out = self.vectorization_layer(sms)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "_stuff = train\n",
    "graphclassifier = GraphModel(\n",
    "    in_channels = _stuff.x.shape[1], \n",
    "    out_channels = np.unique(_stuff.y).shape[0],\n",
    "    hidden_channels=10,\n",
    "    num_layers=2,\n",
    "    num_parameters=2,\n",
    "    num_convolutions=2,\n",
    "    resolution=10,\n",
    ")\n",
    "graphclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080f67ea-477f-4f84-8937-227c37b78646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4823, 0.5177],\n",
       "        [0.4811, 0.5189],\n",
       "        [0.4811, 0.5189],\n",
       "        [0.4806, 0.5194],\n",
       "        [0.4812, 0.5188]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "graphclassifier(train)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec770ec-50c5-4426-b319-8968e478bee0",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a6dddfc-4901-491a-bd17-00e4b93fc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "batch_size = len(train_dataset)\n",
    "data_loader = DataLoader(train_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ce73fcb-0570-43ca-914e-81b37e3702e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current acc 0.775, loss 0.518334150314331, : 100%|█| 100/100 [01:12<00:00,  1.38\n"
     ]
    }
   ],
   "source": [
    "graphclassifier.train()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(graphclassifier.parameters(), lr=1e-2)\n",
    "losses = []\n",
    "with tqdm(range(num_epoch)) as epoch:\n",
    "   for i in epoch:\n",
    "       for stuff in data_loader:\n",
    "            optim.zero_grad()\n",
    "            batch_labels = one_hot(stuff.y).type(torch.float32)\n",
    "            prediction = graphclassifier(stuff)\n",
    "            current_loss = loss(prediction, batch_labels)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                real_classification = prediction.argmax(1)\n",
    "                cst = real_classification[0] if np.unique(real_classification).shape[0] == 1 else None\n",
    "                accuracy = (real_classification == stuff.y).type(torch.float32).mean(0)\n",
    "                losses.append(current_loss.detach().numpy())\n",
    "                epoch.set_description(f\"Current acc {accuracy:.3f}, loss {current_loss.detach().numpy()}, {\"\" if cst is None else f\"constant to {cst}\"}\")\n",
    "            current_loss.backward()\n",
    "            optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8062c6e8-3b61-412e-98fd-777d9e3405be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5426, grad_fn=<DivBackward1>), tensor(0.6842))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphclassifier.eval()\n",
    "test_stuff = next(iter(DataLoader(test_dataset,batch_size=len(test_dataset))))\n",
    "prediction = graphclassifier(test_stuff)\n",
    "verdad = one_hot(test_stuff.y).type(torch.float32)\n",
    "loss(prediction, verdad), (prediction.argmax(1)==test_stuff.y).type(torch.float).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28688f8-55cb-4770-8d73-e620587f4114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
